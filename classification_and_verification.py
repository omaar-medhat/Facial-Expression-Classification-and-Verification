# -*- coding: utf-8 -*-
"""Classification and Verification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wq4NjltBRcK4bLV3ZVEbW0Nhg0kYssqD

TASK (1)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import tensorflow as tf
import keras
import kagglehub

path = kagglehub.dataset_download("apollo2506/facial-recognition-dataset")
print("Path to dataset files:", path)

image_size = (64, 64)

train_dataset = keras.utils.image_dataset_from_directory(
    "/kaggle/input/facial-recognition-dataset/Training/Training",
    labels='inferred',
    shuffle=True,
    validation_split=0.2,
    subset="training",
    image_size=image_size,
    seed=11
)

val_dataset = keras.utils.image_dataset_from_directory(
    "/kaggle/input/facial-recognition-dataset/Training/Training",
    labels='inferred',
    shuffle=True,
    validation_split=0.2,
    subset="validation",
    image_size=image_size,
    seed=11
)

rescale_layer = keras.layers.Rescaling(1.0 / 255)

def apply_rescaling(dataset):
    def rescale_images(images, labels):
        return rescale_layer(images), labels
    return dataset.map(rescale_images)

train_dataset = apply_rescaling(train_dataset)
val_dataset = apply_rescaling(val_dataset)

for images, labels in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy())
        plt.title(f"Label: {labels[i].numpy()}")
        plt.axis("off")
    plt.show()

from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess

def apply_preprocessing(dataset, preprocessing_function):
    def preprocess(images, labels):
        return preprocessing_function(images), labels
    return dataset.map(preprocess)

train_dataset_resnet = apply_preprocessing(train_dataset, resnet_preprocess)
val_dataset_resnet = apply_preprocessing(val_dataset, resnet_preprocess)

train_dataset_vgg = apply_preprocessing(train_dataset, vgg_preprocess)
val_dataset_vgg = apply_preprocessing(val_dataset, vgg_preprocess)

from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50, VGG16

def build_model(base_model):
    model = models.Sequential()
    model.add(base_model)
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(6, activation='softmax'))
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

base_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))
base_resnet.trainable = False
resnet_model = build_model(base_resnet)

early_stopping = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)

history_resnet = resnet_model.fit(
    train_dataset_resnet,
    validation_data=val_dataset_resnet,
    epochs=30,
    callbacks=[early_stopping]
)

base_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))
base_vgg.trainable = False
vgg_model = build_model(base_vgg)

history_vgg = vgg_model.fit(
    train_dataset_vgg,
    validation_data=val_dataset_vgg,
    epochs=30,
    callbacks=[early_stopping]
)

test_dataset = keras.utils.image_dataset_from_directory(
    "/kaggle/input/facial-recognition-dataset/Testing/Testing",
    labels='inferred',
    shuffle=False,
    image_size=image_size,
    seed=11
)

test_dataset = apply_rescaling(test_dataset)
test_dataset_resnet = apply_preprocessing(test_dataset, resnet_preprocess)
test_dataset_vgg = apply_preprocessing(test_dataset, vgg_preprocess)

resnet_test_loss, resnet_test_accuracy = resnet_model.evaluate(test_dataset_resnet)
print(f"ResNet Test Loss: {resnet_test_loss:.4f}")
print(f"ResNet Test Accuracy: {resnet_test_accuracy:.4f}")

vgg_test_loss, vgg_test_accuracy = vgg_model.evaluate(test_dataset_vgg)
print(f"VGG Test Loss: {vgg_test_loss:.4f}")
print(f"VGG Test Accuracy: {vgg_test_accuracy:.4f}")

print("\nModel Comparison:")
if resnet_test_accuracy > vgg_test_accuracy:
    print(f"ResNet performs better with a test accuracy of {resnet_test_accuracy:.4f}")
elif resnet_test_accuracy < vgg_test_accuracy:
    print(f"VGG performs better with a test accuracy of {vgg_test_accuracy:.4f}")
else:
    print("Both models perform equally well.")

def plot_history(history, title):
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title(f"{title} Accuracy")
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title(f"{title} Loss")
    plt.legend()

    plt.show()

plot_history(history_resnet, "ResNet")
plot_history(history_vgg, "VGG")

"""TASK (2)"""

import numpy as np
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Flatten, Layer
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow.keras.backend as K
from sklearn.datasets import fetch_lfw_pairs

lfw_train = fetch_lfw_pairs(subset='train', color=True, resize=1.0)
lfw_test = fetch_lfw_pairs(subset='test', color=True, resize=1.0)

X_train_pairs = lfw_train.pairs
y_train = lfw_train.target
X_test_pairs = lfw_test.pairs
y_test = lfw_test.target

def preprocess_pairs(pairs, target_size=(105, 105)):
    X1, X2 = [], []
    for img1, img2 in pairs:
        img1 = cv2.resize(img1, target_size)
        img2 = cv2.resize(img2, target_size)
        X1.append(img1 / 255.0)
        X2.append(img2 / 255.0)
    return np.array(X1), np.array(X2)

X1_train, X2_train = preprocess_pairs(X_train_pairs)
X1_test, X2_test = preprocess_pairs(X_test_pairs)

class L1DistanceLayer(Layer):
    def call(self, inputs):
        feat_a, feat_b = inputs
        return K.abs(feat_a - feat_b)

def create_simple_network(input_shape=(105, 105, 3)):
    input_layer = Input(shape=input_shape)
    x = Flatten()(input_layer)
    x = Dense(128, activation='relu')(x)
    return Model(inputs=input_layer, outputs=x)

base_network = create_simple_network()

input_a = Input(shape=(105, 105, 3))
input_b = Input(shape=(105, 105, 3))

feat_a = base_network(input_a)
feat_b = base_network(input_b)

distance = L1DistanceLayer()([feat_a, feat_b])
output = Dense(1, activation='sigmoid')(distance)

siamese_model = Model(inputs=[input_a, input_b], outputs=output)
siamese_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = siamese_model.fit(
    [X1_train, X2_train], y_train,
    validation_data=([X1_test, X2_test], y_test),
    batch_size=32,
    epochs=10,
    callbacks=[early_stop]
)

test_loss, test_acc = siamese_model.evaluate([X1_test, X2_test], y_test)
print(f"Final Test Accuracy: {test_acc:.4f}")

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()